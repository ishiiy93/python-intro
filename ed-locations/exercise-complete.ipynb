{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Education Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This activity allows you to practice using the [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/) library to scrape some data from the web. It also allows you to practice using a **Jupyter Notebook** to both document and perform your work. As you can see, you can write _Markdown_, as well as Python\n",
    "\n",
    "**quick tips**\n",
    "- Type `esc`, `m`, `enter` to start writing Markdown rather than code \n",
    "- Type `shift` and `enter` to run a code section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the python libraries, we'll need to ensure they're installed on your machine. You can do this easily by running the following command(s) on your terminal \n",
    "\n",
    "```\n",
    "# Install beautifulsoup using pip on the terminal\n",
    "pip install beautifulsoup4\n",
    "pip install pygeocoder\n",
    "pip install plotly\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be able to import the library inside of this notebook by running the following line of Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs, SoupStrainer as ss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need to import a few other libraries, such as `pandas` to manage our data, and `requests` to make URL requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests as r\n",
    "import pandas as p\n",
    "import re\n",
    "from pygeocoder import Geocoder\n",
    "import plotly.plotly as py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Institution Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first task is to use python to identify the **links to institution pages** on their [website](https://collegecost.ed.gov/catc/Default.aspx). We'll begin by making a request of the page content. Due to peculiarities of how the page is built on the client side, we'll read a local version of the page using the `codecs` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "file = codecs.open(\"college-site.html\", 'r')\n",
    "page_content = file.read()\n",
    "soup = bs(page_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have all the page content, you should open up the [website](https://collegecost.ed.gov/catc/Default.aspx) in your browser to _identify the part of the DOM_ where the relevant information is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the TuitionGrid table\n",
    "table = soup.find(id = 'dvCATWTuitionGrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract each row from the table\n",
    "table_rows = table.find_all('tr', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'http://nces.ed.gov/collegenavigator/?id=142328']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at a single row of your table, and figure out how to extract the address from it\n",
    "table_rows[0]['onclick']\n",
    "re.findall(r\"'(.*?)'\", table_rows[0]['onclick'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting links from table rows\n",
    "\n",
    "In this section, we'll iterate through the table rows and extract the links from each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a simple function to extract the link from each row\n",
    "def extract_url(row):\n",
    "    links = re.findall(r\"'(.*?)'\", row['onclick'])\n",
    "    return links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List to store links\n",
    "links = []\n",
    "\n",
    "# Iterate through table rows and use the `extract_url` function to get the URL and store it in `links`\n",
    "for tr in table_rows:\n",
    "    link = extract_url(tr)\n",
    "    links.append(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through links and extract address from webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write a function to retrieve the address of an institution given it's URL (go to the URL, extract address)\n",
    "def get_address(url):\n",
    "    page = r.get(url)\n",
    "    soup = bs(page.content, 'html.parser')\n",
    "    container = soup.find('div', { \"class\" : \"collegedash\"})\n",
    "    span = container.findAll('span', attrs={'class': None})[0]\n",
    "    # This helped: http://stackoverflow.com/questions/38754940/get-text-after-specific-tag-with-beautiful-soup\n",
    "    text = span.findAll('br')[0].nextSibling\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List to store addresses\n",
    "addresses = []\n",
    "\n",
    "# Iterate through links and use your `get_address` function to get the address and store it in `addresses`\n",
    "for link in links:\n",
    "    address = get_address(link)\n",
    "    addresses.append(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Iterate through the addresses and use the `Geocoder.geocode` function to get the lat/long\n",
    "coordinates = []\n",
    "for address in addresses:\n",
    "    try:\n",
    "        location = Geocoder.geocode(address)\n",
    "        coordinates.append(location.coordinates)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping with Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~michael.k.freeman/7.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to sign-in to plotly: get API key here:https://plot.ly/settings/api\n",
    "# py.sign_in('USERNAME', 'API-KEY')\n",
    "\n",
    "# Plot with plotly, from example: https://plot.ly/python/scatter-plots-on-maps/\n",
    "data = [ dict(\n",
    "        type = 'scattergeo',\n",
    "        locationmode = 'USA-states',\n",
    "        lon = coordinates_df[1],\n",
    "        lat = coordinates_df[0],\n",
    "        mode = 'markers',\n",
    "        marker = dict( \n",
    "            size = 8, \n",
    "            opacity = 0.8,\n",
    "            reversescale = True,\n",
    "            autocolorscale = False,\n",
    "            line = dict(\n",
    "                width=1,\n",
    "                color='rgba(102, 102, 102)'\n",
    "            ),\n",
    "        ))]\n",
    "\n",
    "layout = dict(\n",
    "        title = 'Most Increases in Higher Education Tuition',\n",
    "        colorbar = True,   \n",
    "        geo = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showland = True,\n",
    "            landcolor = \"rgb(250, 250, 250)\",\n",
    "            subunitcolor = \"rgb(217, 217, 217)\",\n",
    "            countrycolor = \"rgb(217, 217, 217)\",\n",
    "            countrywidth = 0.5,\n",
    "            subunitwidth = 0.5        \n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig = dict( data=data, layout=layout )\n",
    "py.iplot( fig, validate=False, filename='tuition-increases' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
